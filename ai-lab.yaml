version: v1.0
application:
  type: language
  name: AI Application
  description: AI Application Being Locally Deployed
  containers:
    - name: llamacpp-server
      contextdir: ./deployment/model_servers/llamacpp_python
      containerfile: ./base/Containerfile
      model-service: true
      backend:
        - llama
      arch:
        - arm64
        - amd64
      ports:
        - 8001
      image: quay.io/jctestorg/llamacpp_python:latest
    - name: streamlit-summary-app
      contextdir: .
      containerfile: Containerfile
      arch:
        - arm64
        - amd64
      ports:
        - 8501
      image: quay.io/jctestorg/test-jul9-3:latest